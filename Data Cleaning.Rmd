---
title: "stats 133 project - data cleaning/processing"
author: "Caleb Williams"
date: '`r Sys.Date()`'
output: pdf_document
---

```{r, message = FALSE, warning = FALSE}

library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(syuzhet)
library(pdftools)
library(quanteda)
library(quanteda.corpora)
library(quanteda.textstats)
library(stringr)
library(ggplot2)
library(readtext)
library(reshape2)
library(wordcloud)
library(wordcloud2)
library(SnowballC)
library(purrr)
library(RColorBrewer)

```


```{r}
set.seed(133)

movie_text <- read.csv('/Users/calebwilliams/Downloads/stats133finalproject/title_year_text.csv')

head(movie_text, 10)
```

# Text Cleaning
```{r}

clean_text <- function(text) {
  text <- tolower(text)
  text <- removeNumbers(text)
  text <- removePunctuation(text) 
  text <- removeWords(text, stopwords("en"))
  text <- stripWhitespace(text)
  text <- stemDocument(text)
  
  # specific transformations
  text <- gsub("mmddyyyy", " ", text)

  return(text)
}

# apply cleaning function
movie_text$text <- sapply(movie_text$text, clean_text)

```


# Tokenization
```{r}
text_tokens <- movie_text %>%
  select(title, text) %>%              
  unnest_tokens(word, text)

```

# Convert to tidy and tf_idf format 
```{r}
# tidy format
tidy_text <- text_tokens %>%
  count(title, word) %>% 
  arrange(desc(n))  

head(tidy_text, 10)
```

```{r}
# tf_idf format
text_tf_idf <- tidy_text %>%                       
  bind_tf_idf(word, title, n) %>%      
  arrange(desc(tf_idf))  

head(text_tf_idf, 10)

```


```{r}
# just year and title 
year_title <- movie_text[,c('year','title')]
year_title


```

# Add year to tf_idf
```{r}
tf_idf_year <- inner_join(year_title, text_tf_idf, by = "title")

head(tf_idf_year)

```

# Add decade to tf_idf_year
```{r}

# Add decade column
tf_idf_decade <- tf_idf_year %>%
  mutate(decade = paste0(floor(year / 10) * 10, "s"))


head(tf_idf_decade)


```



# Export tf_idf format to csv
```{r}
write.csv(text_tf_idf, 'movie_texts_tf_idf.csv')
```




# Tidy to Dtm
```{r}
dtm <- tidy_text %>% 
  cast_dtm(title, word, n)

dtm %>% inspect()

# remove sparse terms 
dtm <- removeSparseTerms(dtm, 0.99)

```

```{r}

dfm <- dtm <- tidy_text %>% 
  cast_dfm(title, word, n)


dfm
```
# Lexical Diversity
```{r}
lexdiv <- textstat_lexdiv(dfm)
lexdiv
```

```{r}

ggplot(lexdiv, aes(x = seq_len(nrow(lexdiv)), y = TTR, group = 1)) +
  geom_line(color = "blue") +  
  scale_x_continuous(breaks = seq_len(nrow(lexdiv)), labels = lexdiv$document) +  # Custom x-axis labels
  labs(title = "Lexical Diversity of 30 Popular Rom Coms",
       x = NULL,
       y = "TTR") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(color = 'black', size = 9, angle = 75, hjust = 1),
          axis.text.y = element_text(color = 'black'))

```




```{r}
# lexical diversity by year


```


# N-grams
```{r}



```

